{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "019965a2",
   "metadata": {},
   "source": [
    "# Reinforcement Learning in Carla - DQN Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e8358",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6344cbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import gym_carla\n",
    "import random\n",
    "import numpy as np\n",
    "import pygame\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import deque, namedtuple\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae8abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "directory = '/opt/carla-simulator/PythonAPI/carla/dist/carla-0.9.11-py3.7-linux-x86_64.egg'\n",
    "try:\n",
    "    sys.path.append(directory)\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd499c",
   "metadata": {},
   "source": [
    "Checking if GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07bbab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if T.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eceb30",
   "metadata": {},
   "source": [
    "Clear GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a5735b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717e7b4",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05b60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DQNAgent import DQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b649f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SegmentationAgent import SegmentationAgent\n",
    "from oldencoder import autoencoder\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db075824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentationUNet(\n",
       "  (conv_final): Conv2d(64, 13, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down_convs): ModuleList(\n",
       "    (0): DownConv(\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): DownConv(\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): DownConv(\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): DownConv(\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): DownConv(\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_convs): ModuleList(\n",
       "    (0): UpConv(\n",
       "      (upconv): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): UpConv(\n",
       "      (upconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): UpConv(\n",
       "      (upconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): UpConv(\n",
       "      (upconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_in): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv_out): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_PERCENTAGE = 0.2  # Amount of data to use for validation\n",
    "TEST_NUM = 10  # Number of images to set aside for testing and visualization\n",
    "NUM_CLASSES = 13  # Total number of classes in the dataset\n",
    "BATCH_SIZE = 16  # Batch size for training\n",
    "IMG_SIZE = 128  # The input size for model\n",
    "DATA_PATH = Path('images')  # Location of the dataset\n",
    "SHUFFLE = True  # Shuffle the dataset before making the split\n",
    "LR = 0.001  # Learning rate for the model\n",
    "EPOCHS = 30  # Number of epochs to train the model\n",
    "DEVICE = 'cuda' if T.cuda.is_available() else 'cpu'  # Device used to train\n",
    "\n",
    "unet = SegmentationAgent(VAL_PERCENTAGE, TEST_NUM, NUM_CLASSES, BATCH_SIZE, IMG_SIZE, DATA_PATH, SHUFFLE, LR, DEVICE)\n",
    "unet.model.load_state_dict(T.load('model4.pt'))\n",
    "unet.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a4a284d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv7): ConvTranspose2d(64, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): ConvTranspose2d(32, 13, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae = autoencoder(1, 13, 0.001, 'ae-models/dummy', 'ae-runs/dummy', T.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))\n",
    "ae.load_state_dict(T.load('ae-models/Clear Noon Dry/ae-1649055310'))\n",
    "ae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19bf0e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to Carla server...\n",
      "Carla server connected!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 2500/2500 [13:27:44<00:00, 19.39s/episodes]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  48464.15215778351  seconds \n",
      "Total Steps:  387651\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'number_of_vehicles': 0,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [-3.0, 0.0, 3.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.4, 0.0, 0.4],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.lincoln*',  # filter for defining ego vehicle\n",
    "    'port': 2000,  # connection port\n",
    "    'town': 'Town03',  # which town to simulate\n",
    "    'task_mode': 'curriculum',  # mode of the task, [random, roundabout (only for Town03)] ######******#####\n",
    "    'max_time_episode': 500,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.25,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 5,  # threshold for out of lane\n",
    "    'desired_speed': 12.5,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 200,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'image_collection': False,\n",
    "    'image_input': True,\n",
    "    'unet': unet,\n",
    "    'ae': ae,\n",
    "    'penalty': 'quadratic'\n",
    "}\n",
    "\n",
    "env = gym.make('carla-v0', params=params)\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "agent = DQNAgent(10000, 1000, 0.95, 0.99997, 0.01, 0.001, 73, 3, 'runs/Curriculum/Linear2', 'models/Curriculum/Linear2', True)\n",
    "# agent.load_model('models/Experiments/Image Collection/carla-agent->r:-230.7414897081867-t:501-ep:35-1647951699')\n",
    "\n",
    "ep_rewards = []\n",
    "total_timesteps = 0\n",
    "batch_size = 512\n",
    "update = 256\n",
    "min_timesteps = 100\n",
    "episodes = 2500\n",
    "agg_stats_every = 10\n",
    "num_inputs = 73\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "for episode in tqdm(range(1, episodes + 1), ascii=True, unit='episodes'):\n",
    "    env.collision_hist = []\n",
    "\n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "\n",
    "    current_s = env.reset()\n",
    "    state = current_s['state']\n",
    "    latent = current_s['latent']\n",
    "    current_state_ = np.concatenate((np.array([state[0], state[1], state[2], state[3], 0, 0, 0, 0, 0]), latent), axis=None)\n",
    "    current_state = np.reshape(current_state_, [1, num_inputs])\n",
    "\n",
    "    done = False\n",
    "    episode_start = time.time()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        action = agent.act(current_state)\n",
    "\n",
    "        new_s, reward, done, info = env.step(action)\n",
    "        a = new_s['state']\n",
    "        b = [info['steer'], info['acceleration'], info['angular_velocity_x'], info['angular_velocity_y'], info['angular_velocity_z']]\n",
    "        c = new_s['latent']\n",
    "        new_state_ = np.concatenate((np.array([a[0], a[1], a[2], a[3], b[0], b[1], b[2], b[3], b[4]]), c), axis=None)\n",
    "        new_state = np.reshape(new_state_, [1, num_inputs])\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        agent.memory.memorise(current_state, action, reward, new_state, done)\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "        total_timesteps += 1\n",
    "\n",
    "        loss = agent.learn(batch_size)\n",
    "\n",
    "        if loss is not None:\n",
    "            agent.tensorboard.add_scalar('Loss', loss.item(), episode)\n",
    "            agent.tensorboard.flush()            \n",
    "\n",
    "        if not total_timesteps % update:\n",
    "            agent.update_target_model()\n",
    "\n",
    "        if done:\n",
    "            ep_end = time.time()\n",
    "            ep_time = ep_end - episode_start                \n",
    "            ep_rewards.append(episode_reward)\n",
    "            agent.tensorboard.add_scalar('Reward/Total Reward', episode_reward, episode)\n",
    "            agent.tensorboard.add_scalar('Epsilon', agent.epsilon, episode)\n",
    "            agent.tensorboard.add_scalar('Episode Length/Timesteps', step, episode)\n",
    "            agent.tensorboard.add_scalar('Episode Length/Seconds', ep_time, episode)\n",
    "            agent.tensorboard.flush()\n",
    "            break\n",
    "\n",
    "    if not episode % agg_stats_every or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-agg_stats_every:])/len(ep_rewards[-agg_stats_every:])\n",
    "        min_reward = min(ep_rewards[-agg_stats_every:])\n",
    "        max_reward = max(ep_rewards[-agg_stats_every:])\n",
    "        agent.tensorboard.add_scalar('Reward/Average Reward', average_reward, episode)\n",
    "        agent.tensorboard.add_scalar('Reward/Minimum Reward', min_reward, episode)\n",
    "        agent.tensorboard.add_scalar('Reward/Maximum Reward', max_reward, episode)\n",
    "        agent.tensorboard.flush()\n",
    "\n",
    "    if not episode % 250:\n",
    "        agent.save_model(round(episode_reward), step, episode)\n",
    "        # min_timesteps = step\n",
    "\n",
    "    if episode in [500, 1500]:\n",
    "        agent.epsilon = 1\n",
    "\n",
    "agent.save_model(round(episode_reward), step, episode)\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print('Training time: ', train_time, ' seconds', '\\nTotal Steps: ', total_timesteps)\n",
    "# print('RGB Images Collected: ', env.rgb_count)\n",
    "# print('Semantic Images Collected: ', env.sem_count)\n",
    "agent.tensorboard.close()\n",
    "pygame.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cacd21bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57916db0",
   "metadata": {},
   "source": [
    "## Agent using AED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd3bf1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from EncoderAgent import EncoderAgent\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b70741d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(512, 64, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv7): ConvTranspose2d(64, 512, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (bn7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (bn11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): ConvTranspose2d(32, 13, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VAL_PERCENTAGE = 0.2  # Amount of data to use for validation\n",
    "TEST_NUM = 10  # Number of images to set aside for testing and visualization\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 13  # Total number of classes in the dataset\n",
    "BATCH_SIZE = 128  # Batch size for training\n",
    "IMG_SIZE = 128  # The input size for model\n",
    "DATA_PATH = Path('images')  # Location of the dataset\n",
    "SHUFFLE = True  # Shuffle the dataset before making the split\n",
    "LR = 0.001  # Learning rate for the model\n",
    "EPOCHS = 30  # Number of epochs to train the model\n",
    "DEVICE = 'cuda' if T.cuda.is_available() else 'cpu'  # Device used to train\n",
    "\n",
    "aed = EncoderAgent(VAL_PERCENTAGE, TEST_NUM, CHANNELS, NUM_CLASSES,\n",
    "                          BATCH_SIZE, IMG_SIZE, DATA_PATH, SHUFFLE, LR, DEVICE, False)\n",
    "aed.model.load_state_dict(T.load('rgb-sem-models/model.pt'))\n",
    "aed.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c64fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'number_of_vehicles': 0,\n",
    "    'number_of_walkers': 0,\n",
    "    'display_size': 256,  # screen size of bird-eye render\n",
    "    'max_past_step': 1,  # the number of past steps to draw\n",
    "    'dt': 0.1,  # time interval between two frames\n",
    "    'discrete': True,  # whether to use discrete control space\n",
    "    'discrete_acc': [-3.0, 0.0, 3.0],  # discrete value of accelerations\n",
    "    'discrete_steer': [-0.4, 0.0, 0.4],  # discrete value of steering angles\n",
    "    'continuous_accel_range': [-3.0, 3.0],  # continuous acceleration range\n",
    "    'continuous_steer_range': [-0.3, 0.3],  # continuous steering angle range\n",
    "    'ego_vehicle_filter': 'vehicle.lincoln*',  # filter for defining ego vehicle\n",
    "    'port': 2000,  # connection port\n",
    "    'town': 'Town03',  # which town to simulate\n",
    "    'task_mode': 'curriculum',  # mode of the task, [random, roundabout (only for Town03)] ######******#####\n",
    "    'max_time_episode': 500,  # maximum timesteps per episode\n",
    "    'max_waypt': 12,  # maximum number of waypoints\n",
    "    'obs_range': 32,  # observation range (meter)\n",
    "    'lidar_bin': 0.25,  # bin size of lidar sensor (meter)\n",
    "    'd_behind': 12,  # distance behind the ego vehicle (meter)\n",
    "    'out_lane_thres': 5,  # threshold for out of lane\n",
    "    'desired_speed': 5.0,  # desired speed (m/s)\n",
    "    'max_ego_spawn_times': 200,  # maximum times to spawn ego vehicle\n",
    "    'display_route': True,  # whether to render the desired route\n",
    "    'pixor_size': 64,  # size of the pixor labels\n",
    "    'pixor': False,  # whether to output PIXOR observation\n",
    "    'image_collection': False,\n",
    "    'image_input': False,\n",
    "    'ae_only': True,\n",
    "    'aed': aed,\n",
    "    'penalty': 'linear2'\n",
    "}\n",
    "\n",
    "env = gym.make('carla-v0', params=params)\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "agent = DQNAgent(10000, 1000, 0.95, 0.99975, 0.01, 0.001, 73, 3, 'runs/Curriculum/Linear2andAED', 'models/Curriculum/Linear2andAED', True)\n",
    "# agent.load_model('models/Experiments/Image Collection/carla-agent->r:-230.7414897081867-t:501-ep:35-1647951699')\n",
    "\n",
    "ep_rewards = []\n",
    "total_timesteps = 0\n",
    "batch_size = 512\n",
    "update = 256\n",
    "min_timesteps = 100\n",
    "episodes = 2500\n",
    "agg_stats_every = 10\n",
    "num_inputs = 73\n",
    "\n",
    "train_start = time.time()\n",
    "\n",
    "for episode in tqdm(range(1, episodes + 1), ascii=True, unit='episodes'):\n",
    "    env.collision_hist = []\n",
    "\n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "\n",
    "    current_s = env.reset()\n",
    "    state = current_s['state']\n",
    "    latent = current_s['latent']\n",
    "    current_state_ = np.concatenate((np.array([state[0], state[1], state[2], state[3], 0, 0, 0, 0, 0]), latent), axis=None)\n",
    "    current_state = np.reshape(current_state_, [1, num_inputs])\n",
    "\n",
    "    done = False\n",
    "    episode_start = time.time()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        action = agent.act(current_state)\n",
    "\n",
    "        new_s, reward, done, info = env.step(action)\n",
    "        a = new_s['state']\n",
    "        b = [info['steer'], info['acceleration'], info['angular_velocity_x'], info['angular_velocity_y'], info['angular_velocity_z']]\n",
    "        c = new_s['latent']\n",
    "        new_state_ = np.concatenate((np.array([a[0], a[1], a[2], a[3], b[0], b[1], b[2], b[3], b[4]]), c), axis=None)\n",
    "        new_state = np.reshape(new_state_, [1, num_inputs])\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        agent.memory.memorise(current_state, action, reward, new_state, done)\n",
    "\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "        total_timesteps += 1\n",
    "\n",
    "        loss = agent.learn(batch_size)\n",
    "\n",
    "        if loss is not None:\n",
    "            agent.tensorboard.add_scalar('Loss', loss.item(), episode)\n",
    "            agent.tensorboard.flush()            \n",
    "\n",
    "        if not total_timesteps % update:\n",
    "            agent.update_target_model()\n",
    "\n",
    "        if done:\n",
    "            ep_end = time.time()\n",
    "            ep_time = ep_end - episode_start                \n",
    "            ep_rewards.append(episode_reward)\n",
    "            agent.tensorboard.add_scalar('Reward/Total Reward', episode_reward, episode)\n",
    "            agent.tensorboard.add_scalar('Epsilon', agent.epsilon, episode)\n",
    "            agent.tensorboard.add_scalar('Episode Length/Timesteps', step, episode)\n",
    "            agent.tensorboard.add_scalar('Episode Length/Seconds', ep_time, episode)\n",
    "            agent.tensorboard.flush()\n",
    "            break\n",
    "\n",
    "    if not episode % agg_stats_every or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-agg_stats_every:])/len(ep_rewards[-agg_stats_every:])\n",
    "        min_reward = min(ep_rewards[-agg_stats_every:])\n",
    "        max_reward = max(ep_rewards[-agg_stats_every:])\n",
    "        agent.tensorboard.add_scalar('Reward/Average Reward', average_reward, episode)\n",
    "        agent.tensorboard.add_scalar('Reward/Minimum Reward', min_reward, episode)\n",
    "        agent.tensorboard.add_scalar('Reward/Maximum Reward', max_reward, episode)\n",
    "        agent.tensorboard.flush()\n",
    "\n",
    "    if not episode % 250:\n",
    "        agent.save_model(round(episode_reward), step, episode)\n",
    "        # min_timesteps = step\n",
    "\n",
    "    if episode in [500, 1500]:\n",
    "        agent.epsilon = 1\n",
    "\n",
    "agent.save_model(round(episode_reward), step, episode)\n",
    "train_end = time.time()\n",
    "train_time = train_end - train_start\n",
    "print('Training time: ', train_time, ' seconds', '\\nTotal Steps: ', total_timesteps)\n",
    "# print('RGB Images Collected: ', env.rgb_count)\n",
    "# print('Semantic Images Collected: ', env.sem_count)\n",
    "agent.tensorboard.close()\n",
    "pygame.quit()\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65041d93a60b93414efebb38827610ec1be4f6b4001eb2d7f80b0fd656cf09d9"
  },
  "kernelspec": {
   "display_name": "Python [conda env:carla]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
